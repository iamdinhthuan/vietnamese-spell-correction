"""
Gradio Interface cho BARTpho Spelling Correction
Load checkpoint m·ªõi nh·∫•t t·ª´ th∆∞ m·ª•c training

Usage:
    python gradio_inference.py

Gradio UI s·∫Ω m·ªü t·∫°i http://localhost:7860
"""

import os
import glob
import re
import torch
import gradio as gr
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# ============================================================================
# C·∫§U H√åNH
# ============================================================================

CHECKPOINT_DIR = "/home/thuan/data/bartpho_vsc/"
MAX_LENGTH = 256
DEFAULT_NUM_BEAMS = 15

# ============================================================================
# H√ÄM T√åM CHECKPOINT M·ªöI NH·∫§T
# ============================================================================

def find_latest_checkpoint(checkpoint_dir):
    """
    T√¨m checkpoint m·ªõi nh·∫•t trong th∆∞ m·ª•c
    
    Args:
        checkpoint_dir: ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a checkpoints
    
    Returns:
        str: ƒê∆∞·ªùng d·∫´n ƒë·∫øn checkpoint m·ªõi nh·∫•t
    """
    # T√¨m t·∫•t c·∫£ c√°c th∆∞ m·ª•c checkpoint-*
    checkpoints = glob.glob(os.path.join(checkpoint_dir, "checkpoint-*"))
    
    if not checkpoints:
        raise ValueError(f"Kh√¥ng t√¨m th·∫•y checkpoint n√†o trong {checkpoint_dir}")
    
    # Sort theo s·ªë step (l·∫•y t·ª´ t√™n th∆∞ m·ª•c)
    checkpoints.sort(key=lambda x: int(x.split("-")[-1]))
    
    latest_checkpoint = checkpoints[-1]
    step_number = int(latest_checkpoint.split("-")[-1])
    
    return latest_checkpoint, step_number

# ============================================================================
# T·∫¢I M√î H√åNH
# ============================================================================

print("=" * 80)
print("BARTpho Spelling Correction - Gradio Interface")
print("=" * 80)

# Ki·ªÉm tra GPU
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Device: {device}")

# T√¨m checkpoint m·ªõi nh·∫•t
print(f"\nT√¨m checkpoint m·ªõi nh·∫•t trong: {CHECKPOINT_DIR}")
try:
    checkpoint_path, step_number = find_latest_checkpoint(CHECKPOINT_DIR)
    print(f"‚úì T√¨m th·∫•y checkpoint: {checkpoint_path}")
    print(f"  Step: {step_number:,}")
except Exception as e:
    print(f"‚úó L·ªói: {e}")
    print("\nKi·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n ho·∫∑c ch·∫°y training tr∆∞·ªõc:")
    print("  python train_bartpho_streaming.py")
    exit(1)

# Load model v√† tokenizer
print("\nƒêang load model v√† tokenizer...")
try:
    tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)
    model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint_path)
    model = model.to(device)
    model.eval()
    print("‚úì Model loaded successfully!")
    print(f"  Parameters: {model.num_parameters():,}")
except Exception as e:
    print(f"‚úó L·ªói khi load model: {e}")
    exit(1)

print("=" * 80)

# ============================================================================
# H√ÄM S·ª¨A L·ªñI CH√çNH T·∫¢
# ============================================================================

def split_sentences(text):
    """
    C·∫Øt vƒÉn b·∫£n th√†nh c√°c c√¢u d·ª±a tr√™n d·∫•u ch·∫•m (.) v√† d·∫•u ch·∫•m h·ªèi (?)
    Gi·ªØ l·∫°i d·∫•u c√¢u ·ªü cu·ªëi m·ªói c√¢u
    
    Args:
        text (str): VƒÉn b·∫£n ƒë·∫ßu v√†o
    
    Returns:
        list: Danh s√°ch c√°c c√¢u
    """
    # T√°ch theo d·∫•u ch·∫•m v√† d·∫•u ch·∫•m h·ªèi, nh∆∞ng gi·ªØ l·∫°i d·∫•u
    # Pattern: split sau d·∫•u . ho·∫∑c ? (v√† kho·∫£ng tr·∫Øng n·∫øu c√≥)
    sentences = re.split(r'([.?])\s*', text)
    
    # Gh√©p l·∫°i d·∫•u c√¢u v·ªõi c√¢u t∆∞∆°ng ·ª©ng
    result = []
    for i in range(0, len(sentences) - 1, 2):
        if sentences[i].strip():  # B·ªè qua c√¢u r·ªóng
            sentence = sentences[i]
            if i + 1 < len(sentences):
                sentence += sentences[i + 1]  # Th√™m d·∫•u c√¢u
            result.append(sentence.strip())
    
    # X·ª≠ l√Ω c√¢u cu·ªëi n·∫øu kh√¥ng c√≥ d·∫•u c√¢u
    if len(sentences) % 2 == 1 and sentences[-1].strip():
        result.append(sentences[-1].strip())
    
    return result

def correct_single_sentence(sentence, num_beams=DEFAULT_NUM_BEAMS, max_length=MAX_LENGTH):
    """
    S·ª≠a l·ªói ch√≠nh t·∫£ cho m·ªôt c√¢u ƒë∆°n
    
    Args:
        sentence (str): C√¢u c√≥ l·ªói ch√≠nh t·∫£
        num_beams (int): S·ªë beams cho beam search
        max_length (int): ƒê·ªô d√†i t·ªëi ƒëa c·ªßa output
    
    Returns:
        str: C√¢u ƒë√£ ƒë∆∞·ª£c s·ª≠a l·ªói
    """
    if not sentence or not sentence.strip():
        return ""
    
    # Tokenize input
    inputs = tokenizer(
        sentence,
        max_length=max_length,
        truncation=True,
        padding=True,
        return_tensors="pt"
    )
    
    # Chuy·ªÉn sang device
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    # Generate
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_length=max_length,
            num_beams=num_beams,
            early_stopping=True,
            no_repeat_ngram_size=2,
        )
    
    # Decode
    corrected_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    return corrected_text

def correct_spelling(text, num_beams=DEFAULT_NUM_BEAMS, max_length=MAX_LENGTH):
    """
    S·ª≠a l·ªói ch√≠nh t·∫£ cho vƒÉn b·∫£n ƒë·∫ßu v√†o
    C·∫Øt vƒÉn b·∫£n th√†nh c√°c c√¢u, s·ª≠a t·ª´ng c√¢u, r·ªìi merge l·∫°i
    
    Args:
        text (str): VƒÉn b·∫£n c√≥ l·ªói ch√≠nh t·∫£
        num_beams (int): S·ªë beams cho beam search
        max_length (int): ƒê·ªô d√†i t·ªëi ƒëa c·ªßa output
    
    Returns:
        str: VƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c s·ª≠a l·ªói
    """
    if not text or not text.strip():
        return ""
    
    # C·∫Øt vƒÉn b·∫£n th√†nh c√°c c√¢u
    sentences = split_sentences(text)
    
    # S·ª≠a t·ª´ng c√¢u
    corrected_sentences = []
    for sentence in sentences:
        corrected = correct_single_sentence(sentence, num_beams, max_length)
        corrected_sentences.append(corrected)
    
    # Merge c√°c c√¢u l·∫°i v·ªõi kho·∫£ng tr·∫Øng
    result = " ".join(corrected_sentences)
    
    return result

# ============================================================================
# GRADIO INTERFACE
# ============================================================================

def gradio_correct_spelling(text, num_beams):
    """
    Wrapper function cho Gradio interface
    """
    try:
        result = correct_spelling(text, num_beams=int(num_beams))
        return result
    except Exception as e:
        return f"L·ªói: {str(e)}"

# T·∫°o Gradio interface
with gr.Blocks(title="BARTpho Spelling Correction") as demo:
    gr.Markdown(f"""
    # üî§ BARTpho Spelling Correction
    
    S·ª≠a l·ªói ch√≠nh t·∫£ ti·∫øng Vi·ªát s·ª≠ d·ª•ng BARTpho
    
    **Checkpoint:** `{checkpoint_path}`  
    **Step:** `{step_number:,}`  
    **Device:** `{device.upper()}`
    """)
    
    with gr.Row():
        with gr.Column():
            input_text = gr.Textbox(
                label="üìù VƒÉn b·∫£n c√≥ l·ªói ch√≠nh t·∫£",
                placeholder="Nh·∫≠p vƒÉn b·∫£n c√≥ l·ªói ch√≠nh t·∫£ v√†o ƒë√¢y...",
                lines=5
            )
            
            with gr.Row():
                num_beams_slider = gr.Slider(
                    minimum=1,
                    maximum=20,
                    value=DEFAULT_NUM_BEAMS,
                    step=1,
                    label="S·ªë beams (c√†ng cao c√†ng ch√≠nh x√°c nh∆∞ng ch·∫≠m h∆°n)"
                )
            
            with gr.Row():
                clear_btn = gr.Button("üóëÔ∏è X√≥a", variant="secondary")
                submit_btn = gr.Button("‚ú® S·ª≠a l·ªói ch√≠nh t·∫£", variant="primary")
        
        with gr.Column():
            output_text = gr.Textbox(
                label="‚úÖ VƒÉn b·∫£n ƒë√£ s·ª≠a l·ªói",
                lines=5
            )
    
    # Examples
    gr.Examples(
        examples=[
            ["ƒê√¢y i√† cac ph∆∞ong ti·ªán vi ph·∫°m ƒë∆∞·ª£c camera ghi h√¨nh.", 15],
            ["Ph·ªï bi·∫øn nhat i√† ioi ƒë·ªó kh√¥ng ƒë√∫ng n∆°i quy d·ªãnh.", 15],
            ["T√¥i ƒëang h·ªçc tap ti√©ng vi√©t ∆° tr∆∞√≤ng ƒëai hoc.", 15],
            ["Hom nay troi mua rat to, toi khong the di hoc duoc.", 15],
        ],
        inputs=[input_text, num_beams_slider],
        outputs=output_text,
        fn=gradio_correct_spelling,
        cache_examples=False,
    )
    
    # Event handlers
    submit_btn.click(
        fn=gradio_correct_spelling,
        inputs=[input_text, num_beams_slider],
        outputs=output_text
    )
    
    input_text.submit(
        fn=gradio_correct_spelling,
        inputs=[input_text, num_beams_slider],
        outputs=output_text
    )
    
    clear_btn.click(
        fn=lambda: ("", ""),
        inputs=None,
        outputs=[input_text, output_text]
    )

# ============================================================================
# LAUNCH
# ============================================================================

if __name__ == "__main__":
    print("\nüöÄ ƒêang kh·ªüi ƒë·ªông Gradio interface...")
    print("   M·ªü tr√¨nh duy·ªát t·∫°i: http://localhost:7860")
    print("   Nh·∫•n Ctrl+C ƒë·ªÉ d·ª´ng server\n")
    
    demo.launch(
        server_name="0.0.0.0",  # Cho ph√©p truy c·∫≠p t·ª´ m·∫°ng n·ªôi b·ªô
        server_port=7860,
        share=True,  # ƒê·∫∑t True n·∫øu mu·ªën share link public
        show_error=True
    )
