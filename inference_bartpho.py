"""
Script inference cho m√¥ h√¨nh BARTpho ƒë√£ fine-tune
S·ª≠ d·ª•ng ƒë·ªÉ s·ª≠a l·ªói ch√≠nh t·∫£ ti·∫øng Vi·ªát

Usage:
    python inference_bartpho.py
    
    ho·∫∑c import v√† s·ª≠ d·ª•ng:
    from inference_bartpho import correct_spelling
    result = correct_spelling("Chay √¨ n·ªôp phat ngu·ªôi")
"""

import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# ============================================================================
# C·∫§U H√åNH
# ============================================================================

MODEL_DIR = "./bartpho_vsc_model"
MAX_LENGTH = 256

# Ki·ªÉm tra GPU
device = "cuda" if torch.cuda.is_available() else "cpu"

# ============================================================================
# T·∫¢I M√î H√åNH
# ============================================================================

print("=" * 80)
print("BARTpho Spelling Correction - Inference")
print("=" * 80)
print(f"Loading model from: {MODEL_DIR}")
print(f"Device: {device}")

try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)
    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_DIR)
    model = model.to(device)
    model.eval()
    print("‚úì Model loaded successfully!")
except Exception as e:
    print(f"‚úó Error loading model: {e}")
    print("\nH√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ hu·∫•n luy·ªán model b·∫±ng c√°ch ch·∫°y:")
    print("  python train_bartpho_spelling.py")
    exit(1)

print("=" * 80)

# ============================================================================
# H√ÄM S·ª¨A L·ªñI CH√çNH T·∫¢
# ============================================================================

def correct_spelling(text, num_beams=5, max_length=MAX_LENGTH):
    """
    S·ª≠a l·ªói ch√≠nh t·∫£ cho vƒÉn b·∫£n ƒë·∫ßu v√†o
    
    Args:
        text (str): VƒÉn b·∫£n c√≥ l·ªói ch√≠nh t·∫£
        num_beams (int): S·ªë beams cho beam search (c√†ng cao c√†ng ch√≠nh x√°c nh∆∞ng ch·∫≠m h∆°n)
        max_length (int): ƒê·ªô d√†i t·ªëi ƒëa c·ªßa output
    
    Returns:
        str: VƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c s·ª≠a l·ªói
    """
    # Tokenize input
    inputs = tokenizer(
        text,
        max_length=max_length,
        truncation=True,
        padding=True,
        return_tensors="pt"
    )
    
    # Chuy·ªÉn sang device
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    # Generate
    with torch.no_grad():
        outputs = model.generate(
            **inputs,
            max_length=max_length,
            num_beams=num_beams,
            early_stopping=True,
            no_repeat_ngram_size=2,
        )
    
    # Decode
    corrected_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
    return corrected_text


def correct_batch(texts, batch_size=8, num_beams=5, max_length=MAX_LENGTH):
    """
    S·ª≠a l·ªói ch√≠nh t·∫£ cho nhi·ªÅu vƒÉn b·∫£n c√πng l√∫c
    
    Args:
        texts (list): List c√°c vƒÉn b·∫£n c√≥ l·ªói
        batch_size (int): K√≠ch th∆∞·ªõc batch
        num_beams (int): S·ªë beams cho beam search
        max_length (int): ƒê·ªô d√†i t·ªëi ƒëa c·ªßa output
    
    Returns:
        list: List c√°c vƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c s·ª≠a l·ªói
    """
    results = []
    
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        
        # Tokenize batch
        inputs = tokenizer(
            batch,
            max_length=max_length,
            truncation=True,
            padding=True,
            return_tensors="pt"
        )
        
        # Chuy·ªÉn sang device
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        # Generate
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_length=max_length,
                num_beams=num_beams,
                early_stopping=True,
                no_repeat_ngram_size=2,
            )
        
        # Decode
        batch_results = tokenizer.batch_decode(outputs, skip_special_tokens=True)
        results.extend(batch_results)
    
    return results


# ============================================================================
# DEMO INTERACTIVE
# ============================================================================

def interactive_demo():
    """
    Ch·∫ø ƒë·ªô demo t∆∞∆°ng t√°c
    """
    print("\n" + "=" * 80)
    print("DEMO T∆Ø∆†NG T√ÅC - S·ª≠a l·ªói ch√≠nh t·∫£ ti·∫øng Vi·ªát")
    print("=" * 80)
    print("Nh·∫≠p vƒÉn b·∫£n c√≥ l·ªói ch√≠nh t·∫£ (ho·∫∑c 'quit' ƒë·ªÉ tho√°t)")
    print("-" * 80)
    
    while True:
        print("\nInput: ", end="")
        text = input().strip()
        
        if text.lower() in ['quit', 'exit', 'q']:
            print("T·∫°m bi·ªát!")
            break
        
        if not text:
            continue
        
        # S·ª≠a l·ªói
        corrected = correct_spelling(text)
        
        print(f"Output: {corrected}")
        print("-" * 80)


# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    # V√≠ d·ª• s·ª≠ d·ª•ng
    print("\nüìù V√ç D·ª§ S·ª¨ D·ª§NG:")
    print("-" * 80)
    
    # Test cases
    test_cases = [
        "Chay √¨ n·ªôp phat ngu·ªôi.",
        "ƒê√¢y i√† cac ph∆∞ong ti·ªán vi ph·∫°m ƒë∆∞·ª£c camera ghi h√¨nh.",
        "Ph·ªï bi·∫øn nhat i√† ioi ƒë·ªó kh√¥ng ƒë√∫ng n∆°i quy d·ªãnh.",
    ]
    
    for i, text in enumerate(test_cases, 1):
        print(f"\n{i}. Input:  {text}")
        corrected = correct_spelling(text)
        print(f"   Output: {corrected}")
    
    print("\n" + "=" * 80)
    
    # Ch·∫°y demo t∆∞∆°ng t√°c
    try:
        interactive_demo()
    except KeyboardInterrupt:
        print("\n\nT·∫°m bi·ªát!")

